{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the SpaCy Package for Semantic Similarity\n",
    "There are different packages in Python for natural language processing, including SpaCy and NLTK. Here, we will be looking into the SpaCy package.\n",
    "\n",
    "## Installing SpaCy and English Pipeline\n",
    "To use this package, first we need to install SpaCy:\n",
    "\n",
    "`pip install -U spacy`\n",
    "\n",
    "We also need to install a language library to use spacy tools:\n",
    "\n",
    "`python -m spacy download en_core_web_lg`\n",
    "\n",
    "*(These are the commands for Mac, so it will be different for Windows/Linux)*. Note that en_core_web_lg is a big file (around 500 MB). There is also en_core_web_sm and en_core_web_md, but we will use the large one since it includes built-in word vectors which allows for better comparisons (our primary goal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Word and Sentence Similarity\n",
    "Now, we can use SpaCy to make comparisons between words, sentences, multiple sentences, and much more. For now, we'll start with the simple tasks.\n",
    "### Word Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify words we want to compare\n",
    "w1 = 'red'\n",
    "w2 = 'bowling'\n",
    "w3 = 'blue'\n",
    "w4 = 'burgundy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn words into spacy objects\n",
    "sw1 = nlp(w1)\n",
    "sw2 = nlp(w2)\n",
    "sw3 = nlp(w3)\n",
    "sw4 = nlp(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of \"red\" to \"bowling\": 0.23\n",
      "Similarity of \"red\" to \"blue\": 0.81\n",
      "Similarity of \"red\" to \"burgundy\": 0.55\n"
     ]
    }
   ],
   "source": [
    "s1 = sw1.similarity(sw2)\n",
    "s2 = sw1.similarity(sw3)\n",
    "s3 = sw1.similarity(sw4)\n",
    "\n",
    "print(f'Similarity of \"{w1}\" to \"{w2}\": {s1:.2f}')\n",
    "print(f'Similarity of \"{w1}\" to \"{w3}\": {s2:.2f}')\n",
    "print(f'Similarity of \"{w1}\" to \"{w4}\": {s3:.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that \"red\" and \"blue\" have the most similarity, which makes sense because they are both very simplistic terms for color. On the other hand, even though \"red\" and \"burgundy\" are more similar in color than \"red\" and \"blue\" are, burgundy is more of a descriptive term that would be used for extra specificity. Using burgundy instead of red gives more context than using blue instead of red. As expected, \"bowling\" and \"red\" had the least similarity.\n",
    "\n",
    "### Sentence Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between: \n",
      "1. The big red dog could barely fit through the door.\n",
      "2. The large blue cat hardly made it through the entrance.\n",
      "Similarity: 0.88\n",
      "\n",
      "Similarity between: \n",
      "1. The big red dog could barely fit through the door.\n",
      "3. Do you want pizza or spaghetti for dinner tonight?\n",
      "Similarity: 0.42\n"
     ]
    }
   ],
   "source": [
    "s1 = nlp(\"The big red dog could barely fit through the door.\")\n",
    "s2 = nlp(\"The large blue cat hardly made it through the entrance.\")\n",
    "s3 = nlp(\"Do you want pizza or spaghetti for dinner tonight?\")\n",
    "ss1 = s1.similarity(s2)\n",
    "ss2 = s1.similarity(s3)\n",
    "\n",
    "print(f'Similarity between: \\n1. {s1}\\n2. {s2}\\nSimilarity: {ss1:.2f}\\n')\n",
    "print(f'Similarity between: \\n1. {s1}\\n3. {s3}\\nSimilarity: {ss2:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that sentence 1 is very similar to sentence 2 with a similarity of 0.88. They use an almost identical sentence structure with very similar vocabularity. The similarity between sentence 1 and sentence 3 is significantly smaller which also makes sense, since the sentences achieve two very different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between: \n",
      "1. The big red dog could barely fit through the door.\n",
      "4. The barely red door fit the big red dog.\n",
      "Similarity: 0.95\n"
     ]
    }
   ],
   "source": [
    "s4 = nlp(\"The barely red door fit the big red dog.\")\n",
    "ss3 = s1.similarity(s4)\n",
    "print(f'Similarity between: \\n1. {s1}\\n4. {s4}\\nSimilarity: {ss3:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that we've used the same words to consruct sentence 4 but it has a different phrasing which changes the meaning. The similarity, however, between 1 and 4 is 0.95 which is even higher than the similarity between sentence 1 and 2. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spacy for Our Project\n",
    "Spacy includes a number of different features used for natural language processing and its applications. There are a few that could be particularly useful for our project:\n",
    "\n",
    "**Sentence Boundary Detection (SBD):** Finding and segmenting individual sentences. We can use this to compare individual sentences to each other when we want to match an input to the movie script line with the highest similarity.\n",
    "\n",
    "**Similarity:** comparing words, text spans, and documents and how similar they are to each other. The application of this is obvious; we want to compare how similar an input is to movie characters!\n",
    "\n",
    "**Training:** Updating and improving a statistical model's predictions. This could help us improve our identification accuracy of a particular character.\n",
    "\n",
    "The similarity between doc and span objects default to the average of the token vectors (words) which means that it doesn't take into account the ordering of the words. We'll want to change this if possible, since we want to take phrasing into account. (This is why sentence 1 and 4 had the highest similarity).\n",
    "\n",
    "*Source: https://spacy.io/usage/spacy-101*\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S1877050919313791\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
