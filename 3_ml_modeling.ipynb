{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling\n",
    "For our purposes, we want to try a few different models to see which one works the best with our data. The first one we will try is Support Vector Machines. Before that, though, we'll need to split our data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/moviedata_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>character_name</th>\n",
       "      <th>line_num</th>\n",
       "      <th>line</th>\n",
       "      <th>unigram_tokens</th>\n",
       "      <th>bigram_unigram_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>0</td>\n",
       "      <td>we're sitting in pastels, this nouvelle northe...</td>\n",
       "      <td>['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...</td>\n",
       "      <td>['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>1</td>\n",
       "      <td>you'll notice that my friends and i all look a...</td>\n",
       "      <td>['you', \"'ll\", 'that', 'my', 'friends', 'and',...</td>\n",
       "      <td>['you', \"'ll\", 'that', 'my', 'friends', 'and',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>2</td>\n",
       "      <td>or can it be worn with a suit?</td>\n",
       "      <td>['or', 'can', 'it', 'be', 'with', 'a', 'suit',...</td>\n",
       "      <td>['or', 'can', 'it', 'be', 'with', 'a', 'suit',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>3</td>\n",
       "      <td>with discreet pinstripes you should wear a sub...</td>\n",
       "      <td>['with', 'you', 'should', 'wear', 'a', 'blue',...</td>\n",
       "      <td>['with', 'you', 'should', 'wear', 'a', 'blue',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>4</td>\n",
       "      <td>van patten looks puffy. has he stopped working...</td>\n",
       "      <td>['van', 'patten', 'looks', 'puffy', '.', 'has'...</td>\n",
       "      <td>['van', 'patten', 'looks', 'puffy', '.', 'has'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movie character_name  line_num  \\\n",
       "0  American Psycho        Bateman         0   \n",
       "1  American Psycho        Bateman         1   \n",
       "2  American Psycho        Bateman         2   \n",
       "3  American Psycho        Bateman         3   \n",
       "4  American Psycho        Bateman         4   \n",
       "\n",
       "                                                line  \\\n",
       "0  we're sitting in pastels, this nouvelle northe...   \n",
       "1  you'll notice that my friends and i all look a...   \n",
       "2                     or can it be worn with a suit?   \n",
       "3  with discreet pinstripes you should wear a sub...   \n",
       "4  van patten looks puffy. has he stopped working...   \n",
       "\n",
       "                                      unigram_tokens  \\\n",
       "0  ['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...   \n",
       "1  ['you', \"'ll\", 'that', 'my', 'friends', 'and',...   \n",
       "2  ['or', 'can', 'it', 'be', 'with', 'a', 'suit',...   \n",
       "3  ['with', 'you', 'should', 'wear', 'a', 'blue',...   \n",
       "4  ['van', 'patten', 'looks', 'puffy', '.', 'has'...   \n",
       "\n",
       "                               bigram_unigram_tokens  \n",
       "0  ['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...  \n",
       "1  ['you', \"'ll\", 'that', 'my', 'friends', 'and',...  \n",
       "2  ['or', 'can', 'it', 'be', 'with', 'a', 'suit',...  \n",
       "3  ['with', 'you', 'should', 'wear', 'a', 'blue',...  \n",
       "4  ['van', 'patten', 'looks', 'puffy', '.', 'has'...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['unigram_tokens']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'clf__kernel': 'linear', 'tfidf__max_df': 0.1, 'tfidf__max_features': 2000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.4603833425261996\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,1))),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [1000, 2000, 5000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__C': [1, 10],\n",
    "    'clf__kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "uni_svm_grid = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "uni_svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", uni_svm_grid.best_params_)\n",
    "print(\"Best score: \", uni_svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/uni_svm_grid.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(uni_svm_grid, 'models/uni_svm_grid.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.460"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__hidden_layer_sizes': (10,), 'tfidf__max_df': 0.2, 'tfidf__max_features': 10000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.4746093031807318\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,1))),\n",
    "    ('clf', MLPClassifier(max_iter=1000, activation = 'relu', solver='adam'))\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [3000, 5000, 10000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__hidden_layer_sizes': [(10,), (20,), (10,10)]\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "uni_mlp_grid = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "uni_mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", uni_mlp_grid.best_params_)\n",
    "print(\"Best score: \", uni_mlp_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/uni_mlp_grid.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(uni_mlp_grid, 'models/uni_mlp_grid.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.469"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['bigram_unigram_tokens']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Here, we will create a pipeline for support vector machines and then tune it to find the best parameters. We will use **k-fold cross validation** to tune, and then find what the best parameters are and what the score is. We will try this for unigrams and unigrams + bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 10, 'clf__kernel': 'linear', 'tfidf__max_df': 0.15, 'tfidf__max_features': 30000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.45971226328369186\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [10000, 20000, 30000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.15],\n",
    "    'clf__C': [1, 10, 100],\n",
    "    'clf__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "bi_svm_grid = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "bi_svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", bi_svm_grid.best_params_)\n",
    "print(\"Best score: \", bi_svm_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/bi_svm_grid.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bi_svm_grid, 'models/bi_svm_grid.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.460"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m bi_mlp_grid \u001b[39m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[39m=\u001b[39mkf, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Fit the GridSearch CV object to the training data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m bi_mlp_grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters: \u001b[39m\u001b[39m\"\u001b[39m, bi_mlp_grid\u001b[39m.\u001b[39mbest_params_)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest score: \u001b[39m\u001b[39m\"\u001b[39m, bi_mlp_grid\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\bella\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', MLPClassifier(max_iter=1000, activation = 'relu', solver='adam'))\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [10000, 20000, 30000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__hidden_layer_sizes': [(10,), (20,), (10,10)]\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "bi_mlp_grid = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "bi_mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", bi_mlp_grid.best_params_)\n",
    "print(\"Best score: \", bi_mlp_grid.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.434"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['line']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'clf__kernel': 'linear', 'tfidf__max_df': 0.1, 'tfidf__max_features': 20000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.4590319911748484\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [10000, 15000, 20000],\n",
    "    'tfidf__max_df': [0.1, 0.5, 0.9],\n",
    "    'clf__C': [1, 10, 100],\n",
    "    'clf__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "seq_svm_grid = GridSearchCV(pipeline3, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "seq_svm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", seq_svm_grid.best_params_)\n",
    "print(\"Best score: \", seq_svm_grid.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.459"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__hidden_layer_sizes': (20,), 'tfidf__max_df': 0.1, 'tfidf__max_features': 5000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.46444658944658956\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MLPClassifier(max_iter=1000, activation = 'relu', solver='adam'))\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [10000, 15000, 20000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__hidden_layer_sizes': [(10,), (20,), (10,10)]\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define GridSearchCV\n",
    "seq_mlp_grid = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "seq_mlp_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", seq_mlp_grid.best_params_)\n",
    "print(\"Best score: \", seq_mlp_grid.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.464"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
