{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling\n",
    "For our purposes, we want to try a few different models to see which one works the best with our data. The first one we will try is Support Vector Machines. Before that, though, we'll need to split our data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/moviedata_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>character_name</th>\n",
       "      <th>line_num</th>\n",
       "      <th>line</th>\n",
       "      <th>unigram_tokens</th>\n",
       "      <th>bigram_unigram_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>0</td>\n",
       "      <td>we're sitting in pastels, this nouvelle northe...</td>\n",
       "      <td>['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...</td>\n",
       "      <td>['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>1</td>\n",
       "      <td>you'll notice that my friends and i all look a...</td>\n",
       "      <td>['you', \"'ll\", 'that', 'my', 'friends', 'and',...</td>\n",
       "      <td>['you', \"'ll\", 'that', 'my', 'friends', 'and',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>2</td>\n",
       "      <td>or can it be worn with a suit?</td>\n",
       "      <td>['or', 'can', 'it', 'be', 'with', 'a', 'suit',...</td>\n",
       "      <td>['or', 'can', 'it', 'be', 'with', 'a', 'suit',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>3</td>\n",
       "      <td>with discreet pinstripes you should wear a sub...</td>\n",
       "      <td>['with', 'you', 'should', 'wear', 'a', 'blue',...</td>\n",
       "      <td>['with', 'you', 'should', 'wear', 'a', 'blue',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Psycho</td>\n",
       "      <td>Bateman</td>\n",
       "      <td>4</td>\n",
       "      <td>van patten looks puffy. has he stopped working...</td>\n",
       "      <td>['van', 'patten', 'looks', 'puffy', '.', 'has'...</td>\n",
       "      <td>['van', 'patten', 'looks', 'puffy', '.', 'has'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             movie character_name  line_num  \\\n",
       "0  American Psycho        Bateman         0   \n",
       "1  American Psycho        Bateman         1   \n",
       "2  American Psycho        Bateman         2   \n",
       "3  American Psycho        Bateman         3   \n",
       "4  American Psycho        Bateman         4   \n",
       "\n",
       "                                                line  \\\n",
       "0  we're sitting in pastels, this nouvelle northe...   \n",
       "1  you'll notice that my friends and i all look a...   \n",
       "2                     or can it be worn with a suit?   \n",
       "3  with discreet pinstripes you should wear a sub...   \n",
       "4  van patten looks puffy. has he stopped working...   \n",
       "\n",
       "                                      unigram_tokens  \\\n",
       "0  ['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...   \n",
       "1  ['you', \"'ll\", 'that', 'my', 'friends', 'and',...   \n",
       "2  ['or', 'can', 'it', 'be', 'with', 'a', 'suit',...   \n",
       "3  ['with', 'you', 'should', 'wear', 'a', 'blue',...   \n",
       "4  ['van', 'patten', 'looks', 'puffy', '.', 'has'...   \n",
       "\n",
       "                               bigram_unigram_tokens  \n",
       "0  ['we', \"'re\", 'sitting', 'in', ',', 'this', 'p...  \n",
       "1  ['you', \"'ll\", 'that', 'my', 'friends', 'and',...  \n",
       "2  ['or', 'can', 'it', 'be', 'with', 'a', 'suit',...  \n",
       "3  ['with', 'you', 'should', 'wear', 'a', 'blue',...  \n",
       "4  ['van', 'patten', 'looks', 'puffy', '.', 'has'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['unigram_tokens']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'clf__kernel': 'linear', 'tfidf__max_df': 0.1, 'tfidf__max_features': 2000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.4603833425261996\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,1))),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [1000, 2000, 5000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__C': [1, 10],\n",
    "    'clf__kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define gGridSearchCV\n",
    "grid_search = GridSearchCV(pipeline3, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.460"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP) (my little pony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,1))),\n",
    "    ('clf', mlp())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [1000, 2000, 5000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.2,],\n",
    "    'clf__hidden_layer_sizes': [(10,), (20,), (10,10)],\n",
    "    'clf__kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define gGridSearchCV\n",
    "grid_search = GridSearchCV(pipeline3, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['bigram_unigram_tokens']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "Here, we will create a pipeline for support vector machines and then tune it to find the best parameters. We will use **k-fold cross validation** to tune, and then find what the best parameters are and what the score is. We will try this for unigrams and unigrams + bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'clf__kernel': 'linear', 'tfidf__max_df': 0.05, 'tfidf__max_features': 10000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.463761720904578\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [10000, 20000, 30000],\n",
    "    'tfidf__max_df': [0.05, 0.1, 0.15],\n",
    "    'clf__C': [1, 10, 100],\n",
    "    'clf__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define gGridSearchCV\n",
    "grid_search = GridSearchCV(pipeline3, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.464"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing\n",
    "X = data['line']\n",
    "y = data['character_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'clf__C': 1, 'clf__kernel': 'linear', 'tfidf__max_df': 0.1, 'tfidf__max_features': 20000, 'tfidf__stop_words': 'english'}\n",
      "Best score:  0.4590319911748484\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid to search over\n",
    "param_grid = {\n",
    "    'tfidf__stop_words': ['english', None],\n",
    "    'tfidf__max_features': [20000, 30000, 40000],\n",
    "    'tfidf__max_df': [0.1, 0.5, 0.9],\n",
    "    'clf__C': [1, 10, 100],\n",
    "    'clf__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Creating K-Fold cross-validation model\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# Define gGridSearchCV\n",
    "grid_search = GridSearchCV(pipeline3, param_grid, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearch CV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.459"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
